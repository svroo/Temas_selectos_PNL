{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div  align='right'><h3>26/09/2023</h3></div>\n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "Cual es la diferencia entre:\n",
    "\n",
    "- Comí una pizza con amigos\n",
    "\n",
    "- Comi una pizza con aceitunas\n",
    "\n",
    "  \n",
    "\n",
    "verbo : comer\n",
    "\n",
    "  \n",
    "\n",
    "acción: comer\n",
    "\n",
    "  \n",
    "\n",
    "objeto: pizza con aceitunas\n",
    "\n",
    "  \n",
    "\n",
    "objeto : pizza\n",
    "\n",
    "  \n",
    "\n",
    "complemento : con amigos\n",
    "\n",
    "  \n",
    "\n",
    "y con:\n",
    "\n",
    "- Compartí un pizza con amigos\n",
    "\n",
    "  \n",
    "\n",
    "acción : compartir\n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "Hay seis niveles de comprensión, que son los siguientes:\n",
    "\n",
    "- Nivel fonetico : Como las palabras son pronunciadas\n",
    "\n",
    "- Nivel morfologico : Se estudia la estructura de las palabras y se clasifican y delimitarlas. Por ejemplo: Pablo comproó una Thermomix, Pablo : Sujero, compró : verbo, una : articulo indefinido, thermomix : objeto\n",
    "\n",
    "- Nivel sintáctico : Realiza un análisis de la sintaxis el cual incluye la acción de dividir na oración en cada uno de sus componentes.\n",
    "\n",
    "- Nivel semantico : Es un complemento del anterior y busca entender el significado de la oración, usando el contexto de la oración.\n",
    "\n",
    "- Nivel discursivo : Examina el significado de la oración en relación a otra oración en el texto o parráfo del mismo documento.\n",
    "\n",
    "- Nivel pragmatico : ocupa del análisis de las oraciones como se usa ante diversas situaciones.\n",
    "\n",
    "  \n",
    "\n",
    "Son inseparables y se complemetan entre si, el obetivo deL nlp es usarla todas juntas en una computadora.\n",
    "\n",
    "  \n",
    "\n",
    "Las librerias que podemos utilizar son :\n",
    "\n",
    "- NLTK : Es una libreria abierta muy popular de Python, provee herramientas y recursos para trabajar con datos de lenguaje humano (texto) para tareas de procesamiento del lenguaje natural (NLP). Fue desarrollado por el Grupo de Procesamiento de Lenguaje Natural de la universidad de Pennsylvania y es apmplimanete utilizado por investigadores,desarroladores y estudiantes en el campo de la NLP.\n",
    "\n",
    "  \n",
    "\n",
    "Usos:\n",
    "\n",
    "- Tokenización de Texto : NLTK ofrece herramientas para dividir el texto en palabras individuales u oraciones, un paso fundamental en varias tareas de NLP\n",
    "- Etiquetado de parte del discurso : NLTK puede etiquetar palabras en un texto con su correspondiente parte del discurso (e.j., sujeto, verbo, adjetivo), lo cual es crucial para comprender la estructura y el significado de las oraciones.\n",
    "- Análisis de sentimientos : NLTK puede ser usada para determinar el sentimiento o el tono emocional en un pedazo de texto, ayudan a las empresas a medir la opinón publica sobre productos, servicios o eventos.\n",
    "- Clasificacion de Texto : NLTK permite la creación de modelos para categorizar texto en clases predefinidas, como detección de spam, clasificación de temas o categorización basada en sentimientos.\n",
    "- Reconocimiento de entidades nombradas (NER): NLTK puede identificar y clasificar entidades nombradas en texto, como nombres de personas, organizaciones, ubicaciones y fechas.\n",
    "- Modelado de lenguaje: NLTK admite la creación de modelos de lenguaje que predicen la probabilidad de que aparezca una palabra o secuencia de palabras en un contexto determinado, lo cual es útil para tareas como la autocompletar.\n",
    "- Recuperación de información: NLTK puede ayudar a crear motores de búsqueda o sistemas de recuperación de información que clasifiquen y recuperen documentos relevantes en función de las consultas de los usuarios.\n",
    "- Análisis de concordancia y colocación: NLTK puede ayudar a analizar colocaciones de palabras (palabras que aparecen juntas con frecuencia) y generar concordancias (contextos en los que aparecen palabras) para términos específicos en un texto.\n",
    "- Traducción automática: si bien NLTK no está diseñado principalmente para la traducción automática, puede usarse como base para desarrollar sistemas de traducción simples.\n",
    "- Aprendizaje y enseñanza de idiomas: NLTK puede ayudar a crear herramientas educativas para estudiantes de idiomas al proporcionar recursos para analizar texto, comprender la gramática y aprender vocabulario en contexto.\n",
    "Natural Language Toolkit (NLTK) es un conjunto de bibliotecas y programas para el procesamiento del lenguaje natural (NLP) en Python.  Proporciona una amplia gama de herramientas, recursos y algoritmos para trabajar con datos del lenguaje humano.  Estas son algunas de las características clave de NLTK:\n",
    "\t- Utilidades de procesamiento de texto: NLTK ofrece una variedad de funciones para el preprocesamiento de texto, como tokenización, derivación, lematización y eliminación de palabras vacías.  \n",
    "\t- Etiquetado de parte del discurso: NLTK incluye herramientas para asignar etiquetas de parte del discurso a palabras en un texto, lo que permite el análisis sintáctico y gramatical.  \n",
    "\t- Reconocimiento de entidades nombradas (NER): NLTK puede identificar y clasificar entidades nombradas, como nombres de personas, organizaciones, ubicaciones y más.  \n",
    "\t- Análisis de sentimientos: NLTK incluye módulos de análisis de sentimientos que ayudan a clasificar el texto como positivo, negativo o neutral, según su tono emocional.\n",
    "\t- Análisis: NLTK proporciona analizadores que se pueden utilizar para analizar la estructura gramatical de oraciones y generar árboles sintácticos.  \n",
    "\t- Corporas y recursos lingüísticos: NLTK viene con una amplia gama de corpus (conjuntos de datos textuales) y recursos lingüísticos que se pueden utilizar para entrenar y probar modelos de PNL.  \n",
    "\t- Modelado de lenguaje: NLTK admite la creación de modelos de lenguaje que predicen la probabilidad de que aparezcan palabras o secuencias de palabras en contextos específicos.  \n",
    "\t- Recuperación de información: NLTK incluye herramientas para crear motores de búsqueda, indexar documentos y clasificar resultados según su relevancia.  \n",
    "\t- Análisis de concordancia y colocación: NLTK proporciona funciones para analizar colocaciones de palabras (pares de palabras comunes) y generar concordancias (ocurrencias contextuales) para palabras específicas.  \n",
    "\t- Aprendizaje automático: si bien no es tan extenso como las bibliotecas dedicadas al aprendizaje automático, NLTK incluye algunos algoritmos básicos de aprendizaje automático para tareas como clasificación y agrupación.  \n",
    "\t- Categorización y clasificación: NLTK admite tareas de categorización de texto, donde los documentos de texto se asignan a categorías predefinidas.\n",
    "\n",
    "Arquitectura:\n",
    "\t- La arquitectura de NLTK no está tan formalizada como la de otros sistemas de software. Está organizado como una colección de módulos que cubren diferentes áreas de la PNL. Los usuarios pueden importar y utilizar módulos específicos según sus requisitos. La arquitectura de NLTK está diseñada para proporcionar flexibilidad y modularidad, permitiendo a los usuarios elegir las funcionalidades que necesitan mientras trabajan con datos de texto.\n",
    "\n",
    "- Ventajas y desventajas\n",
    "\t- Ventajas\n",
    "\t\t- La biblioteca de NLP más conocida y completa con muchas extensiones de terceros\n",
    "\t\t- Soporta el mayor número de idiomas en comparación con otras bibliotecas\n",
    "\t- Desventajas\n",
    "\t\t- Dificil de aprender y usar\n",
    "\t\t- Lento\n",
    "\t\t- Solo divide le texto por oraciones, sin analizar la estructura semántica\n",
    "\t\t- Sin modelos de redes neuronales\n",
    "\n",
    "\n",
    "# TrexBlob\n",
    "\n",
    "TextBlob se basa en NLTK y Pattern. Tiene una excelente API para todas las operaciones comunes de PNL. Es una biblioteca más práctica concentrada en el uso diario. \n",
    " Es fantástico para la creación de prototipos iniciales en casi todos los proyectos de PNL. Desafortunadamente, hereda el bajo rendimiento de NLTK y, por lo tanto, no es bueno para el uso en producción a gran escala.\n",
    " ## Funciones de TextBlob\n",
    "\n",
    "Tokenización, POS, NER, clasificación, análisis de sentimientos, corrección ortográfica, análisis, traducción y detección de idioma. \n",
    "#### Casos de uso de TextBlob\n",
    "- Casos de uso de PNL de ejemplo de inicio rápido de TextBlob:\n",
    "\t- Análisis de los sentimientos\n",
    "\t- Corrección ortográfica\n",
    "\t- Traducción y detección de idiomas\n",
    "\n",
    "### Pros y contras\n",
    "- Pros:\n",
    "\t- Interfaz intuitiva y fácil de usar para la biblioteca NLTK\n",
    "\t- Proporciona traducción y detección de idiomas con tecnología de Google Translate\n",
    "- Contras:\n",
    "\t- Lenta\n",
    "\t- No tiene modelos de redes neuronales\n",
    "\t- No tiene vectores de palabras integrados\n",
    "\n",
    "\n",
    "# Stanford Core NLP\n",
    "**Stanford CoreNLP** es una biblioteca de procesamiento de lenguaje natural (NLP) desarrollada por el grupo de NLP de Stanford¹⁹. Aquí tienes una descripción general de sus características, casos de uso y ventajas y desventajas.\n",
    "\n",
    "**Características**:\n",
    "- CoreNLP permite a los usuarios derivar anotaciones lingüísticas para texto, incluyendo límites de tokens y oraciones, partes del habla, entidades nombradas, valores numéricos y de tiempo, análisis de dependencia y de constituyentes, correferencia, sentimiento, atribuciones de citas y relaciones¹.\n",
    "- Actualmente, CoreNLP admite 8 idiomas: árabe, chino, inglés, francés, alemán, húngaro, italiano y español¹.\n",
    "- El núcleo de CoreNLP es el pipeline. Los pipelines toman texto en bruto, ejecutan una serie de anotadores de NLP en el texto y producen un conjunto final de anotaciones¹.\n",
    "- Los pipelines producen CoreDocuments, objetos de datos que contienen toda la información de anotación, accesibles con una API sencilla y serializables a un Google Protocol Buffer¹.\n",
    "\n",
    "**Casos de uso**:\n",
    "- CoreNLP puede ser utilizado a través de la línea de comandos, en código Java, o con llamadas a un servidor, y puede ser ejecutado en múltiples idiomas incluyendo árabe, chino, inglés, francés, alemán y español.\n",
    "- CoreNLP y las herramientas acompañantes son apropiadas para cualquier aplicación que requiera tecnología de lenguaje humano o herramientas de procesamiento de lenguaje natural necesarias para manejar texto de lenguaje humano (es decir, minería de texto, inteligencia empresarial, búsqueda web, análisis de sentimientos, comprensión del lenguaje natural, etc.).\n",
    "\n",
    "**Ventajas y desventajas**:\n",
    "No pude encontrar información específica sobre las ventajas y desventajas de Stanford CoreNLP. Sin embargo, en general, las bibliotecas de NLP como Stanford CoreNLP pueden tener las siguientes ventajas y desventajas:\n",
    "\n",
    "**Ventajas**:\n",
    "- Proporcionan una amplia gama de funcionalidades para tareas de NLP.\n",
    "- Son altamente personalizables y extensibles.\n",
    "- Pueden manejar grandes cantidades de datos de texto.\n",
    "\n",
    "**Desventajas**:\n",
    "- Pueden tener una curva de aprendizaje empinada, especialmente para los principiantes.\n",
    "- La calidad de los resultados puede depender en gran medida de la calidad de los datos de entrada.\n",
    "- Algunas tareas de NLP pueden requerir una gran cantidad de recursos computacionales.\n",
    "\n",
    "# Spacy\n",
    "Es una biblioteca avanzada de **PNL** disponible en Python y Cython. Está orientado al rendimiento y funciona junto con marcos de aprendizaje profundo como *TensorFlow* o *PyTorch*.\n",
    "\n",
    "Viene con modelos estadísticos previamente entrenados y vectores de palabras. Cuenta con toenización para más de 5 idiomas, modelos de redes neuronales convolucionales para etiquetar, analizar y reconocimiento de entidades con nombre.\n",
    "\n",
    "#### Caracteristicas de spaCy\n",
    "- Tokenizacion\n",
    "- POS\n",
    "- NER\n",
    "- clasificación\n",
    "- análisis de sentimientos\n",
    "- análisis de dependencias\n",
    "- vectores de palabras\n",
    "\n",
    "- Casos de uso de spaCy\n",
    "\t- El autocompletado de búsqueda (y autocorrección) es un tipo popular de PNL que muchas personas usan a diario\n",
    "\t- Analiza las reseñas en linea. Extrae los temas clave cubiertos por las revisiones sin tener que pasar por todos ellos. Ayudar a los vendedores / minoristas a obtener comentarios de los consumidores en forma de temas (extraídos de las revisiones de los consumidores).\n",
    "\t- Resumen automático de currículums con NER - Evalúe los currículums de un vistazo para facilitar la evaluación de los currículums de un vistazo rápido, simplificando así el esfuerzo requerido en la preselección de candidatos entre una pila de currículums.\n",
    "\n",
    "- Ventajas y desventajas\n",
    "\t- Ventajas\n",
    "\t\t- Rápido\n",
    "\t\t- Fácil de aprender y usar\n",
    "\t\t- Utiliza redes neuronales para entrenar modelos\n",
    "\t- Contras\n",
    "\t\t- menos flexibilidad en comparación con NLTK\n",
    "\n",
    "# Textacy\n",
    "**Textacy** es una biblioteca de Python para realizar una variedad de tareas de procesamiento de lenguaje natural (NLP), construida sobre la biblioteca de alto rendimiento spaCy. Aquí tienes una descripción general de sus características, casos de uso y ventajas y desventajas.\n",
    "\n",
    "**Características**:\n",
    "- Acceso y extensión de la funcionalidad principal de spaCy para trabajar con uno o muchos documentos a través de métodos convenientes y extensiones personalizadas.\n",
    "- Carga de conjuntos de datos preparados con contenido de texto y metadatos, desde discursos del Congreso hasta literatura histórica y comentarios de Reddit.\n",
    "- Limpieza, normalización y exploración de texto en bruto antes de procesarlo con spaCy.\n",
    "- Extracción de información estructurada de documentos procesados, incluyendo n-grams, entidades, acrónimos, términos clave y triples SVO.\n",
    "- Comparación de cadenas y secuencias utilizando una variedad de métricas de similitud.\n",
    "- Tokenización y vectorización de documentos y luego entrenamiento, interpretación y visualización de modelos de temas.\n",
    "- Cálculo de estadísticas de legibilidad y diversidad léxica del texto, incluyendo el nivel de grado Flesch-Kincaid, la facilidad de lectura multilingüe de Flesch y la relación tipo-token.\n",
    "\n",
    "**Casos de uso**:\n",
    "- Textacy puede ser útil en una variedad de casos de uso de NLP, como la limpieza y preprocesamiento de texto, la detección automática de idioma, la tokenización y vectorización de documentos, y el entrenamiento e interpretación de modelos de temas³.\n",
    "- También puede ser útil para cargar conjuntos de datos preparados que contienen tanto contenido de texto como información, como comentarios de Reddit, discursos del Congreso y libros históricos³.\n",
    "- Además, puede proporcionar la facilidad de extraer características como n-grams, entidades, acrónimos, frases clave y triples SVO como datos estructurados de documentos procesados³.\n",
    "\n",
    "**Ventajas y desventajas**:\n",
    "No pude encontrar información específica sobre las ventajas y desventajas de Textacy. Sin embargo, en general, las bibliotecas de NLP como Textacy pueden tener las siguientes ventajas y desventajas:\n",
    "\n",
    "**Ventajas**:\n",
    "- Proporcionan una amplia gama de funcionalidades para tareas de NLP.\n",
    "- Son altamente personalizables y extensibles.\n",
    "- Pueden manejar grandes cantidades de datos de texto.\n",
    "\n",
    "**Desventajas**:\n",
    "- Pueden tener una curva de aprendizaje empinada, especialmente para los principiantes.\n",
    "- La calidad de los resultados puede depender en gran medida de la calidad de los datos de entrada.\n",
    "- Algunas tareas de NLP pueden requerir una gran cantidad de recursos computacionales.\n",
    "\n",
    "# Gensim\n",
    "Originalmente fue desarrollado para el modelado de temas, pero hoy en día admite una variedad de otras tareas de PNL, pero no es un kit de herramientas completo de PNL como NLTK o spaCy. Su caso de uso principal es trabajar con vectores de palabras.\n",
    "\n",
    "Los vectores de palabras mejoran nuestra capacidad para analizar las relaciones entre palabras, oraciones y documentos. Estamos asumiendo que el significado de una palabra puede ser inferido por la compañía que mantiene. Como el dicho, \"muéstrame a tus amigos, y te diré quién eres\".\n",
    "\n",
    "### Caracteristicas de Gensim\n",
    "implementaciones paralelizadas de algoritmos fastText, word2vec y doc2vec, análisis semántico latente (LSA, LSI, SVD), factorización de matriz no negativa (NMF), asignación latente de Dirichlet (LDA), tf-idf.\n",
    "\n",
    "- Casos de uso de Gensim\n",
    "\t- Convertir palabras y documentos en vectores\n",
    "\t- Encontrar similitud de texto\n",
    "\t- Resumen de texto\n",
    "\n",
    "- Ventajas y desventajas\n",
    "\t- Ventajas\n",
    "\t\t- Interfaz intuitiva\n",
    "\t\t- Implementación eficiente de algorimos populares\n",
    "\t\t- Escalable : puede ejecutar análisis semántico latente y asignación de Dirichlet latente en un clúster de equipos\n",
    "\t- Desventajas\n",
    "\t\t- Diseñado principalmente para el modelado de texto no supervisado\n",
    "\t\t- No implemete una tubería NLP completa, debe usarse con otras librerias como Spacy o NLTK\n",
    "\t\n",
    "\n",
    "# pyLDAVIS\n",
    "**pyLDAvis** es una biblioteca de Python para la visualización interactiva de modelos de temas. Aquí tienes una descripción general de sus características, casos de uso y ventajas y desventajas.\n",
    "\n",
    "**Características**:\n",
    "- pyLDAvis está diseñado para ayudar a los usuarios a interpretar los temas en un modelo de temas que ha sido ajustado a un corpus de datos de texto.\n",
    "- La biblioteca extrae información de un modelo de temas LDA ajustado para informar una visualización interactiva basada en la web.\n",
    "- La visualización está diseñada para ser utilizada dentro de un cuaderno IPython, pero también puede ser guardada en un archivo HTML independiente para facilitar su compartición.\n",
    "\n",
    "**Casos de uso**:\n",
    "- pyLDAvis es útil para visualizar e interpretar los resultados de los modelos de temas.\n",
    "- Puede ser utilizado para analizar conjuntos de datos de texto reales, como tweets.\n",
    "- La visualización proporcionada por pyLDAvis puede ayudar a entender mejor los temas identificados por el modelo.\n",
    "\n",
    "**Ventajas y desventajas**:\n",
    "No pude encontrar información específica sobre las ventajas y desventajas de pyLDAvis. Sin embargo, en general, las bibliotecas de visualización de modelos de temas como pyLDAvis pueden tener las siguientes ventajas y desventajas:\n",
    "\n",
    "**Ventajas**:\n",
    "- Proporcionan una forma visual e interactiva de explorar los resultados de los modelos de temas.\n",
    "- Pueden ayudar a los usuarios a interpretar mejor los temas identificados por el modelo.\n",
    "- Son útiles para analizar y visualizar grandes conjuntos de datos de texto.\n",
    "\n",
    "**Desventajas**:\n",
    "- Pueden tener una curva de aprendizaje empinada, especialmente para los principiantes.\n",
    "- La calidad de los resultados puede depender en gran medida de la calidad de los datos de entrada.\n",
    "- Algunas tareas pueden requerir una gran cantidad de recursos computacionales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div aling='right'><h3> 27/09/2023</h3></div>\n",
    "\n",
    "# Análisis Morfológico\n",
    "\n",
    "Consiste en determinar la **categoria gramatical** de cada palabra que forma una oración. \n",
    "\n",
    "### ¿Cómo se analiza morfológicamente?\n",
    "Se toma cada palabra y se determina a qué categoria pertence. VAmos a verlo con un ejemplo muy sencillo:\n",
    "\n",
    "<p><quote> El ave blanca vuela</quote></p>\n",
    "\n",
    "- El : articulao femenino\n",
    "\n",
    "#### Clases de palabras\n",
    "- Determinantes: son palabras qeu acompañan al sustantivo para aportar información sobre el mismo: género, número, situaiones en el espacio, posesión. Hay diferentes clases de determinantes:\n",
    "    - Determinativos (él, la, las, los) o indeterminados (un, una, unos, unas)\n",
    "    - Demostrativos: indican la proximidad o lejanía del sustantivo (este, esta, ese, aquel, aquella)\n",
    "    - Posesivos: indican a quien pertenece lo designado por el sustantivo (mi, mio, tu, tuyo, nuestro, vuestro)\n",
    "    - Indefinidos: INdican una cantidad no determinada de lo nombrado (algunos, pocos, muchos, bastante)\n",
    "    - Numerales: señalan orden o cantidad precisa (uno, dos, tercero, cuarto, mitad, doble)\n",
    "    - Interrogativos: acompañan para hacer preguntas (qué, cuánta, cuál)\n",
    "    - Exclamativos: sirven para expresar sorpresa o emoción (qué, cuánto, cuál)\n",
    "\n",
    "# Nombres o sustantivos\n",
    "Son las palabras que nombran a seres vivos, cosas, ideas, sentimientos o cualidades. SEgún su significado pueden ser:\n",
    "- Comounes, si se refieren a seres u obetos en general (árbol, muer, perro) o propios, cuando designan a seres o lugares para distinguilos de los demás de su misma especio (María, Guatemala)\n",
    "- Concretos, cuando se refiere a lo que se pueden percibir con los sentidos (libro, carne, mesa) o abstractos, si designan cosas que no se pueden percibir con los sentidos (amistad, dolor, miedo)\n",
    "- Contables, sis se pueden contar (perro, cama, manzana) o incontables, si se refiere a objetos o sustancias no separables (amor, agua, viento)\n",
    "- Individuales, cuando se refiere a un solo objeto contable (arbol, lobo, hombre) o colectivos, cuando designan a un grupo de objetos contables (bosque, manada, gente)\n",
    "\n",
    "Un sustantivo puede pertenecer a todos los grupos: mesa, es un sustantivo común, concreto, contable e individual.\n",
    "\n",
    "Los sustantivos tienen además:\n",
    "- número: singular o plural\n",
    "- género: masculino, femenino\n",
    "\n",
    "# Adjetivo\n",
    "Son palabras que complementan a un sustantivo, modificándolo y dando más información acerca de él. Expresan caracteristicas atribuidas al sustantivo, que pueden se cualidades, número, pertenencia.\n",
    "\n",
    "se pueden clasificar por:\n",
    "- Número : singular o plural\n",
    "- genero : masculino o femenino\n",
    "\n",
    "# Verbos\n",
    "Son palabras que expresan acción, existencia, estado o condición del sueto. Están formados por la **raíz**, que es la parti invariable del verbo y la desinencia, que esl a parte que varía cuando conjugamos el verbo y nos indica la persona, el número, el tiempo, el modo, etc. \n",
    "\n",
    "cuando análisamos un verbo debemos indicar:\n",
    "- conjugación\n",
    "- numero\n",
    "- tiempo\n",
    "- modo\n",
    "\n",
    "# Pronombre\n",
    "Son palabras que sustituyen al nombre para evitar su repetición. Pueden ser:\n",
    "- personales: reemplazan a la persona gramátical y van delante de los verbos (yo, tu, él, ella, nosotros, nosotras, vosotros, vosotras, ellos, ellas)\n",
    "- **Demostrativos, posesivos, indefinidos, numerales, interragativos**\n",
    "\n",
    "# Presposición\n",
    "Son palabras que sirven para unir o conectar otras palabras\n",
    "\n",
    "# Adverbio\n",
    "Es una palabra que complemetna a un verbo, un adjetivo, otro adverbio o a una oración\n",
    "\n",
    "# conjunción\n",
    "Sirve palra unir palabras en una oración o enlazar oraciones simples. Puede ser\n",
    "- Coordinantes\n",
    "- **Subodinantes**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['es',\n",
       " ',',\n",
       " 'cierto',\n",
       " '¿',\n",
       " 'que',\n",
       " '¡',\n",
       " 'tu',\n",
       " ',',\n",
       " 'casa',\n",
       " 'es',\n",
       " 'más',\n",
       " 'bonita',\n",
       " 'que',\n",
       " 'la',\n",
       " '?',\n",
       " '!']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizar(sentence: str) -> list[str,]:\n",
    "    \"\"\"Tokenizar\n",
    "    Regresa una cadena separando cada uno de sus palabras y caracteres como un elemento individual\n",
    "\n",
    "    Args:\n",
    "        sentence (str): cadena que se quiere tokenizar\n",
    "\n",
    "    Returns:\n",
    "        list[str,]: Lista con las palabras tokenizadas o minimizadas a su minimo\n",
    "    \"\"\"\n",
    "    aux = ''\n",
    "    signos = [',', '.', '?', '¿', '!', '¡', ':', ';', '(', ')', '-', '_', '+', '&']\n",
    "    tokens = list()\n",
    "    for i in sentence:\n",
    "        if i != ' ' and i not in signos:\n",
    "            aux += i\n",
    "        \n",
    "        if i == ' ':\n",
    "            tokens.append(aux)\n",
    "            aux = ''\n",
    "            \n",
    "        if i in signos: \n",
    "            tokens.append(i)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "tokenizar('es cierto, ¿que ¡tu casa, es más bonita que la mia?!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "tok = WhitespaceTokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo \n",
    "Ejemplo usando la libreria spacy, en ingles y en español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "# Cargamos el modelo de spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se obtiene informacion del ususario para varios tipos de oraciones\n",
    "interrogative_sentences = 'what is the weather like today?' # enunciado interrogativo\n",
    "declarative_sentence = 'The weather is sunny' # enunciado declarativo\n",
    "complex_sentence = 'I went to the store, but they wew clased, so i had to go another store.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se procesa las sentencias\n",
    "interrogative_doc = nlp(interrogative_sentences)\n",
    "declarative_doc = nlp(declarative_sentence)\n",
    "complex_doc = nlp(complex_sentence)\n",
    "\n",
    "compil = {\n",
    "    'Interrogative doc' : interrogative_doc, \n",
    "    'Declarative doc' : declarative_doc, \n",
    "    'Oracion compleja' : complex_doc    \n",
    "}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrogative doc\n",
      "what PRON\n",
      "is AUX\n",
      "the DET\n",
      "weather NOUN\n",
      "like ADP\n",
      "today NOUN\n",
      "? PUNCT\n",
      "\n",
      "Declarative doc\n",
      "The DET\n",
      "weather NOUN\n",
      "is AUX\n",
      "sunny ADJ\n",
      "\n",
      "Oracion compleja\n",
      "I PRON\n",
      "went VERB\n",
      "to ADP\n",
      "the DET\n",
      "store NOUN\n",
      ", PUNCT\n",
      "but CCONJ\n",
      "they PRON\n",
      "wew VERB\n",
      "clased VERB\n",
      ", PUNCT\n",
      "so CCONJ\n",
      "i PRON\n",
      "had VERB\n",
      "to PART\n",
      "go VERB\n",
      "another DET\n",
      "store NOUN\n",
      ". PUNCT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc in compil.keys():\n",
    "    print(doc)\n",
    "    # Imprimimos el analisis\n",
    "    for token in compil[doc]:\n",
    "        print(token.text, token.pos_)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación del ejemplo de anterior pero usando palabras en español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se obtiene informacion del ususario para varios tipos de oraciones\n",
    "interrogative_sentences_es = '¿Hace mucho calor?' # enunciado interrogativo\n",
    "declarative_sentence_es = 'El clima esta muy caliente' # enunciado declarativo\n",
    "complex_sentence_es = \"Fui a la tienda, pero estaba cerrada, así que tuve que ir a otra tienda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se procesa las sentencias\n",
    "interrogative_doc_es= nlp(interrogative_sentences_es)\n",
    "declarative_doc_es = nlp(declarative_sentence_es)\n",
    "complex_doc_es = nlp(complex_sentence_es)\n",
    "\n",
    "compil = {\n",
    "    'Documento interrogativo:' : interrogative_doc_es, \n",
    "    'Documento declarativo:' : declarative_doc_es, \n",
    "    'Oracion compleja:' : complex_doc_es    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento interrogativo:\n",
      "¿ PROPN\n",
      "Hace PROPN\n",
      "mucho NOUN\n",
      "calor NOUN\n",
      "? PUNCT\n",
      "\n",
      "Documento declarativo:\n",
      "El PROPN\n",
      "clima PROPN\n",
      "esta PROPN\n",
      "muy PROPN\n",
      "caliente PROPN\n",
      "\n",
      "Oracion compleja:\n",
      "Fui PROPN\n",
      "a DET\n",
      "la ADJ\n",
      "tienda NOUN\n",
      ", PUNCT\n",
      "pero PROPN\n",
      "estaba PROPN\n",
      "cerrada PROPN\n",
      ", PUNCT\n",
      "así PROPN\n",
      "que PROPN\n",
      "tuve NOUN\n",
      "que VERB\n",
      "ir VERB\n",
      "a DET\n",
      "otra ADJ\n",
      "tienda NOUN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc in compil.keys():\n",
    "    print(doc)\n",
    "    # Imprimimos el analisis\n",
    "    for token in compil[doc]:\n",
    "        print(token.text, token.pos_)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PNLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
